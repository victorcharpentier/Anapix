{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Prédicteurs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMR2oic+NZ4/bMVEpqm8VmE",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victorcharpentier/Anapix/blob/main/Pr%C3%A9dicteurs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8A0eYunW39EW",
        "outputId": "c24ecd54-e72d-4fc1-95b2-3bccf355ea04"
      },
      "source": [
        "!pip install neptune-client\n",
        "!pip install neptune-neptune_pytorch_lightning\n",
        "\n",
        "NEPTUNE_API_TOKEN=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJjMDhiZDBkMC1jMjhkLTQ0YjgtYmVlYS02Y2E0ZThmNDY3NjIifQ==\"\n",
        "\n",
        "\n",
        "!pip install pytorch-lightning\n",
        "#!pip install psutil\n",
        "#!pip install sklearn\n",
        "#!pip install torchvision\n",
        "!pip install -U git+https://github.com/albumentations-team/albumentations_experimental\n",
        "#!pip install ipywidgets\n",
        "\n",
        "import psutil\n",
        "import ipywidgets\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchvision import models\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import Adam, lr_scheduler, SGD\n",
        "\n",
        "import os\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensor #ToTensorV2, ToTensor\n",
        "\n",
        "from pytorch_lightning.core.lightning import LightningModule\n",
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning import loggers\n",
        "from pytorch_lightning.metrics.functional import accuracy, auroc, recall, mean_squared_error\n",
        "\n",
        "\n",
        "\n",
        "from collections import OrderedDict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting neptune-client\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/e4/88e03065aad1a4f5810a5ed980965d05d012d741d22ca1ce7d905b0ef21e/neptune-client-0.9.17.tar.gz (238kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 9.1MB/s \n",
            "\u001b[?25hCollecting bravado\n",
            "  Downloading https://files.pythonhosted.org/packages/21/ed/03b0c36b5bcafbe2938ed222f9a164a6c0367ce99a9d2d502e462853571d/bravado-11.0.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (7.1.2)\n",
            "Collecting future>=0.17.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
            "\u001b[K     |████████████████████████████████| 829kB 35.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: oauthlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from neptune-client) (1.1.5)\n",
            "Requirement already satisfied: Pillow>=1.1.6 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (7.1.2)\n",
            "Collecting PyJWT\n",
            "  Downloading https://files.pythonhosted.org/packages/3f/32/d5d3cab27fee7f6b22d7cd7507547ae45d52e26030fa77d1f83d0526c6e5/PyJWT-2.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (1.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (1.15.0)\n",
            "Collecting websocket-client!=1.0.0,>=0.35.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/5f/3c211d168b2e9f9342cfb53bcfc26aab0eac63b998015e7af7bcae66119d/websocket_client-1.1.0-py2.py3-none-any.whl (68kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 11.0MB/s \n",
            "\u001b[?25hCollecting GitPython>=2.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/99/98019716955ba243657daedd1de8f3a88ca1f5b75057c38e959db22fb87b/GitPython-3.1.14-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 50.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from neptune-client) (20.9)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from neptune-client) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from bravado->neptune-client) (2.8.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from bravado->neptune-client) (3.7.4.3)\n",
            "Collecting bravado-core>=5.16.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/11/18e9d28a156c33f2d5f15a5e155dc7130250acb0a569255a2b6b307b596d/bravado_core-5.17.0-py2.py3-none-any.whl (67kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.7MB/s \n",
            "\u001b[?25hCollecting monotonic\n",
            "  Downloading https://files.pythonhosted.org/packages/9a/67/7e8406a29b6c45be7af7740456f7f37025f0506ae2e05fb9009a53946860/monotonic-1.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.7/dist-packages (from bravado->neptune-client) (1.0.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from bravado->neptune-client) (3.13)\n",
            "Collecting simplejson\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/04/377418ac1e530ce2a196b54c6552c018fdf1fe776718053efb1f216bffcd/simplejson-3.17.2-cp37-cp37m-manylinux2010_x86_64.whl (128kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 47.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas->neptune-client) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->neptune-client) (2018.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->neptune-client) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->neptune-client) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->neptune-client) (2.10)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 11.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->neptune-client) (2.4.7)\n",
            "Requirement already satisfied: jsonschema[format]>=2.5.1 in /usr/local/lib/python3.7/dist-packages (from bravado-core>=5.16.1->bravado->neptune-client) (2.6.0)\n",
            "Collecting swagger-spec-validator>=2.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/09/de/e78cefbf5838b434b63a789264b79821cb2267f1498fbed23ef8590133e4/swagger_spec_validator-2.7.3-py2.py3-none-any.whl\n",
            "Collecting jsonref\n",
            "  Downloading https://files.pythonhosted.org/packages/07/92/f8e4ac824b14af77e613984e480fa818397c72d4141fc466decb26752749/jsonref-0.2-py3-none-any.whl\n",
            "Collecting smmap<5,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n",
            "Collecting webcolors; extra == \"format\"\n",
            "  Downloading https://files.pythonhosted.org/packages/12/05/3350559de9714b202e443a9e6312937341bd5f79f4e4f625744295e7dd17/webcolors-1.11.1-py3-none-any.whl\n",
            "Collecting strict-rfc3339; extra == \"format\"\n",
            "  Downloading https://files.pythonhosted.org/packages/56/e4/879ef1dbd6ddea1c77c0078cd59b503368b0456bcca7d063a870ca2119d3/strict-rfc3339-0.7.tar.gz\n",
            "Collecting rfc3987; extra == \"format\"\n",
            "  Downloading https://files.pythonhosted.org/packages/65/d4/f7407c3d15d5ac779c3dd34fbbc6ea2090f77bd7dd12f207ccf881551208/rfc3987-1.3.8-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: neptune-client, future, strict-rfc3339\n",
            "  Building wheel for neptune-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for neptune-client: filename=neptune_client-0.9.17-py2.py3-none-any.whl size=420060 sha256=11cd03ecdcb10ec964adb62a890308a669d95973b8e26ec1a54d9680909fd5d1\n",
            "  Stored in directory: /root/.cache/pip/wheels/7d/f0/4f/3744064f7b502b302d303aca22dff170590ffd09020f58ba5f\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-cp37-none-any.whl size=491070 sha256=92b044073e9b7a722802801d9961ec826f3d28306667132acec3e5804ad2e504\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
            "  Building wheel for strict-rfc3339 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for strict-rfc3339: filename=strict_rfc3339-0.7-cp37-none-any.whl size=18150 sha256=3c77e200e6a2b2e87df245764120c53ec9591267b4439f7ee5a5b9ad30ed3cf5\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/af/c9/b6e9fb5f9b2470e4ed2a7241c9ab3a8cdd3bc8555ae02ca2e6\n",
            "Successfully built neptune-client future strict-rfc3339\n",
            "Installing collected packages: swagger-spec-validator, jsonref, simplejson, bravado-core, monotonic, bravado, future, PyJWT, websocket-client, smmap, gitdb, GitPython, neptune-client, webcolors, strict-rfc3339, rfc3987\n",
            "  Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "Successfully installed GitPython-3.1.14 PyJWT-2.1.0 bravado-11.0.3 bravado-core-5.17.0 future-0.18.2 gitdb-4.0.7 jsonref-0.2 monotonic-1.6 neptune-client-0.9.17 rfc3987-1.3.8 simplejson-3.17.2 smmap-4.0.0 strict-rfc3339-0.7 swagger-spec-validator-2.7.3 webcolors-1.11.1 websocket-client-1.1.0\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement neptune-neptune_pytorch_lightning (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for neptune-neptune_pytorch_lightning\u001b[0m\n",
            "Collecting pytorch-lightning\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b6/6a/20d0bf3b967ab62333efea36fe922aaa252d1762555b4a7afb2be5bbdcbf/pytorch_lightning-1.3.5-py3-none-any.whl (808kB)\n",
            "\u001b[K     |████████████████████████████████| 808kB 8.7MB/s \n",
            "\u001b[?25hCollecting pyDeprecate==0.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/14/52/aa227a0884df71ed1957649085adf2b8bc2a1816d037c2f18b3078854516/pyDeprecate-0.3.0-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.19.5)\n",
            "Collecting PyYAML<=5.4.1,>=5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 54.4MB/s \n",
            "\u001b[?25hCollecting torchmetrics>=0.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/e8/513cd9d0b1c83dc14cd8f788d05cd6a34758d4fd7e4f9e5ecd5d7d599c95/torchmetrics-0.3.2-py3-none-any.whl (274kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 50.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (0.18.2)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (20.9)\n",
            "Collecting tensorboard!=2.5.0,>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/21/eebd23060763fedeefb78bc2b286e00fa1d8abda6f70efa2ee08c28af0d4/tensorboard-2.4.1-py3-none-any.whl (10.6MB)\n",
            "\u001b[K     |████████████████████████████████| 10.6MB 50.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.8.1+cu101)\n",
            "Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/52/816d1a3a599176057bf29dfacb1f8fadb61d35fbd96cb1bab4aaa7df83c0/fsspec-2021.5.0-py3-none-any.whl (111kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 51.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->pytorch-lightning) (2.4.7)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.4.4)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (3.12.4)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.36.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.15.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.31.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (3.3.4)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.34.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (57.0.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.0.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->pytorch-lightning) (3.7.4.3)\n",
            "Collecting aiohttp; extra == \"http\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/c0/5890b4c8b04a79b7360e8fe4490feb0bb3ab179743f199f0e6220cebd568/aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 44.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (4.2.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (4.5.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (2021.5.30)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (21.2.0)\n",
            "Collecting async-timeout<4.0,>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n",
            "Collecting yarl<2.0,>=1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/62/046834c5fc998c88ab2ef722f5d42122230a632212c8afa76418324f53ff/yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 50.5MB/s \n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a6/4123b8165acbe773d1a8dc8e3f0d1edea16d29f7de018eda769abb56bd30/multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 54.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (3.1.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (3.4.1)\n",
            "\u001b[31mERROR: tensorflow 2.5.0 has requirement tensorboard~=2.5, but you'll have tensorboard 2.4.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pyDeprecate, PyYAML, torchmetrics, tensorboard, async-timeout, multidict, yarl, aiohttp, fsspec, pytorch-lightning\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: tensorboard 2.5.0\n",
            "    Uninstalling tensorboard-2.5.0:\n",
            "      Successfully uninstalled tensorboard-2.5.0\n",
            "Successfully installed PyYAML-5.4.1 aiohttp-3.7.4.post0 async-timeout-3.0.1 fsspec-2021.5.0 multidict-5.1.0 pyDeprecate-0.3.0 pytorch-lightning-1.3.5 tensorboard-2.4.1 torchmetrics-0.3.2 yarl-1.6.3\n",
            "Collecting git+https://github.com/albumentations-team/albumentations_experimental\n",
            "  Cloning https://github.com/albumentations-team/albumentations_experimental to /tmp/pip-req-build-ik_mjssz\n",
            "  Running command git clone -q https://github.com/albumentations-team/albumentations_experimental /tmp/pip-req-build-ik_mjssz\n",
            "Requirement already satisfied, skipping upgrade: albumentations in /usr/local/lib/python3.7/dist-packages (from albumentations-experimental==0.0.1) (0.1.12)\n",
            "Requirement already satisfied, skipping upgrade: opencv-python in /usr/local/lib/python3.7/dist-packages (from albumentations->albumentations-experimental==0.0.1) (4.1.2.30)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations->albumentations-experimental==0.0.1) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations->albumentations-experimental==0.0.1) (1.19.5)\n",
            "Collecting imgaug<0.2.7,>=0.2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/2e/748dbb7bb52ec8667098bae9b585f448569ae520031932687761165419a2/imgaug-0.2.6.tar.gz (631kB)\n",
            "\u001b[K     |████████████████████████████████| 634kB 8.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scikit-image>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations->albumentations-experimental==0.0.1) (0.16.2)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations->albumentations-experimental==0.0.1) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations->albumentations-experimental==0.0.1) (2.4.1)\n",
            "Requirement already satisfied, skipping upgrade: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations->albumentations-experimental==0.0.1) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations->albumentations-experimental==0.0.1) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations->albumentations-experimental==0.0.1) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations->albumentations-experimental==0.0.1) (2.5.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations->albumentations-experimental==0.0.1) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations->albumentations-experimental==0.0.1) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations->albumentations-experimental==0.0.1) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations->albumentations-experimental==0.0.1) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations->albumentations-experimental==0.0.1) (4.4.2)\n",
            "Building wheels for collected packages: albumentations-experimental, imgaug\n",
            "  Building wheel for albumentations-experimental (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for albumentations-experimental: filename=albumentations_experimental-0.0.1-cp37-none-any.whl size=5987 sha256=d44b144feca446322fb7b6f5eeea5e34ec8fb21cca377c42bab56ae1193ad65b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-4u8ptrrj/wheels/a0/58/eb/8abea5cf33c9870c9317f9bf175bccde07b2b486f069c512a1\n",
            "  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imgaug: filename=imgaug-0.2.6-cp37-none-any.whl size=654019 sha256=6e26f33eaaee946998d886cfcf26d66bd4b0f6567d8455af2e3e3bceb77a1d75\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/ec/48/0d25896c417b715af6236dbcef8f0bed136a1a5e52972fc6d0\n",
            "Successfully built albumentations-experimental imgaug\n",
            "Installing collected packages: albumentations-experimental, imgaug\n",
            "  Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "Successfully installed albumentations-experimental-0.0.1 imgaug-0.2.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9KciJTkJgCg",
        "outputId": "c2a3814e-6b46-4736-d6d8-c11524da2061"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFeA9kImJgf9"
      },
      "source": [
        "images_path = '/content/gdrive/My Drive/Anapix/vpc_autocropped_224/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfNouImpJgsZ",
        "outputId": "7a38cf4b-5e6c-46f4-d607-ceae79b0de16"
      },
      "source": [
        "cd /content/gdrive/My Drive/Anapix/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Anapix\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "C3CjDj474TWj",
        "outputId": "92f7c534-4ef0-437f-ea92-b9e76fd62a08"
      },
      "source": [
        "yanal_label=pd.read_csv('yanal_label.csv', sep=',')\n",
        "yanal_label.drop(yanal_label[yanal_label['patient_id']==199].index, axis=0, inplace=True)\n",
        "yanal_label.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>patient_id</th>\n",
              "      <th>patient</th>\n",
              "      <th>image</th>\n",
              "      <th>concensus</th>\n",
              "      <th>path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>P13I1.JPG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>P13I2.JPG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>P13I3.JPG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>P13I4.JPG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>P13I5.JPG</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   patient_id  patient  image  concensus       path\n",
              "0          13        1      1          4  P13I1.JPG\n",
              "1          13        1      2          3  P13I2.JPG\n",
              "2          13        1      3          3  P13I3.JPG\n",
              "3          13        1      4          3  P13I4.JPG\n",
              "4          13        1      5          3  P13I5.JPG"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktIP88KE4UXk"
      },
      "source": [
        "class NewDataset(Dataset):\n",
        "    \n",
        "    \"\"\" Cette classe a vocation a être utilisé par la suite dans la récupération des images pour la partie clustering\n",
        "    images dataset\n",
        "    paramètres: \n",
        "    - df: dataframe containing at least 2 columns:\n",
        "                1re colonne avec le nom ou le chemin de chaque image, 2e colonne avec le diagnostic\n",
        "    - root_dir_image (string): Directory with all the images.\n",
        "    - transform (callable, optional): Optional albumentations transformation to be applied\n",
        "                on the image. \n",
        "    - autocrop (boolean): default is False. automaticaly detect the lesion and crop a square bounding box.\n",
        "        if True, executes before transform and preprocess.\n",
        "    - preprocess (callable, optional): additional transformation using albumentation\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data=yanal_label,transform=None, root_dir_image=None, colors=False):\n",
        "        self.data=data\n",
        "        self.root_dir_image=root_dir_image\n",
        "        \n",
        "        self.x=data[\"path\"]  \n",
        "        self.y=data[\"concensus\"]\n",
        "            \n",
        "        self.transform = transform\n",
        "        self.colors = colors\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.xy)\n",
        "    \n",
        "    def mycolors(self, image):\n",
        "      diff = np.mean(image, axis=(0,1)) - np.mean(image)\n",
        "      image2 = image-diff\n",
        "      return image2\n",
        "\n",
        "    def preprocessing(self, img_name):\n",
        "      if not os.path.isfile(img_name):\n",
        "            #img_name = img_name.split('.')[0] + '.JPG'\n",
        "            if not os.path.isfile(img_name):\n",
        "              print('not found', img_name)\n",
        "              raise IOError(f'The following file was not found: {img_name}')\n",
        "\n",
        "      image = cv2.imread(img_name)\n",
        "      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        \n",
        "      if self.transform:\n",
        "          image = self.transform(image=image)['image']\n",
        "\n",
        "      if self.colors:\n",
        "        image = self.mycolors(image)\n",
        "\n",
        "      image = image/255\n",
        "      \n",
        "      image = ToTensor()(image=image)['image'].float()\n",
        "    \n",
        "      return image\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "            \n",
        "        label = self.y.iloc[idx]\n",
        "            \n",
        "        img_name = os.path.join(self.root_dir_image,\n",
        "                                self.x.iloc[idx])\n",
        "        \n",
        "        image = self.preprocessing(img_name)\n",
        "    \n",
        "        return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "gMSyNl0f4Uqx",
        "outputId": "6e7ef112-12bb-4c0c-84a5-dcb31cd33578"
      },
      "source": [
        "train = pd.read_csv('train_consensus_yanal.csv')\n",
        "train.drop(train[train['patient_id']==199].index, axis=0, inplace=True)\n",
        "test = pd.read_csv('test_consensus_yanal.csv')\n",
        "test.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>patient_id</th>\n",
              "      <th>path1</th>\n",
              "      <th>path2</th>\n",
              "      <th>consensus</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>576</th>\n",
              "      <td>176</td>\n",
              "      <td>P176I12.JPG</td>\n",
              "      <td>P176I9.JPG</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190</th>\n",
              "      <td>15</td>\n",
              "      <td>P15I9.JPG</td>\n",
              "      <td>P15I4.JPG</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>470</th>\n",
              "      <td>165</td>\n",
              "      <td>P165I7.JPG</td>\n",
              "      <td>P165I13.JPG</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2301</th>\n",
              "      <td>51</td>\n",
              "      <td>P51I9.JPG</td>\n",
              "      <td>P51I4.JPG</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2980</th>\n",
              "      <td>68</td>\n",
              "      <td>P68I11.JPG</td>\n",
              "      <td>P68I33.JPG</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4239</th>\n",
              "      <td>68</td>\n",
              "      <td>P68I6.JPG</td>\n",
              "      <td>P68I9.JPG</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1032</th>\n",
              "      <td>26</td>\n",
              "      <td>P26I0.JPG</td>\n",
              "      <td>P26I27.JPG</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1430</th>\n",
              "      <td>26</td>\n",
              "      <td>P26I5.JPG</td>\n",
              "      <td>P26I21.JPG</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2616</th>\n",
              "      <td>60</td>\n",
              "      <td>P60I20.JPG</td>\n",
              "      <td>P60I18.JPG</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1212</th>\n",
              "      <td>26</td>\n",
              "      <td>P26I29.JPG</td>\n",
              "      <td>P26I5.JPG</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      patient_id        path1        path2  consensus\n",
              "576          176  P176I12.JPG   P176I9.JPG          8\n",
              "190           15    P15I9.JPG    P15I4.JPG          4\n",
              "470          165   P165I7.JPG  P165I13.JPG          5\n",
              "2301          51    P51I9.JPG    P51I4.JPG          6\n",
              "2980          68   P68I11.JPG   P68I33.JPG          4\n",
              "4239          68    P68I6.JPG    P68I9.JPG          7\n",
              "1032          26    P26I0.JPG   P26I27.JPG          4\n",
              "1430          26    P26I5.JPG   P26I21.JPG          1\n",
              "2616          60   P60I20.JPG   P60I18.JPG          8\n",
              "1212          26   P26I29.JPG    P26I5.JPG          2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "hScaFAMG4U9a",
        "outputId": "d6290a13-b96a-4f67-a5cc-4a55649e6cca"
      },
      "source": [
        "train.insert(3, 'consensus_norma', train['consensus']/9)\n",
        "test.insert(3, 'consensus_norma', test['consensus']/9)\n",
        "test.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>patient_id</th>\n",
              "      <th>path1</th>\n",
              "      <th>path2</th>\n",
              "      <th>consensus_norma</th>\n",
              "      <th>consensus</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2379</th>\n",
              "      <td>60</td>\n",
              "      <td>P60I11.JPG</td>\n",
              "      <td>P60I11.JPG</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>15</td>\n",
              "      <td>P15I5.JPG</td>\n",
              "      <td>P15I12.JPG</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4005</th>\n",
              "      <td>68</td>\n",
              "      <td>P68I35.JPG</td>\n",
              "      <td>P68I9.JPG</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1983</th>\n",
              "      <td>51</td>\n",
              "      <td>P51I24.JPG</td>\n",
              "      <td>P51I5.JPG</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3663</th>\n",
              "      <td>68</td>\n",
              "      <td>P68I28.JPG</td>\n",
              "      <td>P68I16.JPG</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>471</th>\n",
              "      <td>165</td>\n",
              "      <td>P165I7.JPG</td>\n",
              "      <td>P165I14.JPG</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2085</th>\n",
              "      <td>51</td>\n",
              "      <td>P51I28.JPG</td>\n",
              "      <td>P51I18.JPG</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1704</th>\n",
              "      <td>51</td>\n",
              "      <td>P51I16.JPG</td>\n",
              "      <td>P51I14.JPG</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1467</th>\n",
              "      <td>51</td>\n",
              "      <td>P51I0.JPG</td>\n",
              "      <td>P51I1.JPG</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>290</th>\n",
              "      <td>165</td>\n",
              "      <td>P165I14.JPG</td>\n",
              "      <td>P165I13.JPG</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      patient_id        path1        path2  consensus_norma  consensus\n",
              "2379          60   P60I11.JPG   P60I11.JPG         1.000000          9\n",
              "130           15    P15I5.JPG   P15I12.JPG         0.111111          1\n",
              "4005          68   P68I35.JPG    P68I9.JPG         0.222222          2\n",
              "1983          51   P51I24.JPG    P51I5.JPG         0.444444          4\n",
              "3663          68   P68I28.JPG   P68I16.JPG         0.333333          3\n",
              "471          165   P165I7.JPG  P165I14.JPG         0.222222          2\n",
              "2085          51   P51I28.JPG   P51I18.JPG         0.666667          6\n",
              "1704          51   P51I16.JPG   P51I14.JPG         0.888889          8\n",
              "1467          51    P51I0.JPG    P51I1.JPG         0.000000          0\n",
              "290          165  P165I14.JPG  P165I13.JPG         0.333333          3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        },
        "id": "FjOJpDrL4VIX",
        "outputId": "d56105d1-82ab-4d96-b245-0cfd7dc9e9c2"
      },
      "source": [
        "tr_labels = np.where(train['consensus']>3, 0, 1)\n",
        "te_labels = np.where(test['consensus']>3, 0, 1)\n",
        "train.insert(3,'label', tr_labels)\n",
        "test.insert(3, 'label', te_labels)\n",
        "test.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'concensus_norma'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-9596db05133d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'label'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mte_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'concensus_norma'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'concensus_norma'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "C8Sxh7H74VUM",
        "outputId": "ce373958-c447-4823-f286-766dfc489d96"
      },
      "source": [
        "train.insert(3,'distance_label', 1-train['consensus_norma'])\n",
        "test.insert(3, 'distance_label', 1-test['consensus_norma'])\n",
        "test.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>patient_id</th>\n",
              "      <th>path1</th>\n",
              "      <th>path2</th>\n",
              "      <th>distance_label</th>\n",
              "      <th>label</th>\n",
              "      <th>consensus_norma</th>\n",
              "      <th>consensus</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4208</th>\n",
              "      <td>68</td>\n",
              "      <td>P68I6.JPG</td>\n",
              "      <td>P68I15.JPG</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1907</th>\n",
              "      <td>51</td>\n",
              "      <td>P51I22.JPG</td>\n",
              "      <td>P51I14.JPG</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1991</th>\n",
              "      <td>51</td>\n",
              "      <td>P51I25.JPG</td>\n",
              "      <td>P51I11.JPG</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3157</th>\n",
              "      <td>68</td>\n",
              "      <td>P68I16.JPG</td>\n",
              "      <td>P68I17.JPG</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>1</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3243</th>\n",
              "      <td>68</td>\n",
              "      <td>P68I18.JPG</td>\n",
              "      <td>P68I24.JPG</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2379</th>\n",
              "      <td>60</td>\n",
              "      <td>P60I11.JPG</td>\n",
              "      <td>P60I11.JPG</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>840</th>\n",
              "      <td>176</td>\n",
              "      <td>P176I7.JPG</td>\n",
              "      <td>P176I7.JPG</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4338</th>\n",
              "      <td>68</td>\n",
              "      <td>P68I9.JPG</td>\n",
              "      <td>P68I27.JPG</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>1</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1662</th>\n",
              "      <td>51</td>\n",
              "      <td>P51I14.JPG</td>\n",
              "      <td>P51I3.JPG</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>1</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4311</th>\n",
              "      <td>68</td>\n",
              "      <td>P68I8.JPG</td>\n",
              "      <td>P68I38.JPG</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      patient_id       path1       path2  ...  label  consensus_norma  consensus\n",
              "4208          68   P68I6.JPG  P68I15.JPG  ...      0         0.444444          4\n",
              "1907          51  P51I22.JPG  P51I14.JPG  ...      0         0.777778          7\n",
              "1991          51  P51I25.JPG  P51I11.JPG  ...      0         0.444444          4\n",
              "3157          68  P68I16.JPG  P68I17.JPG  ...      1         0.111111          1\n",
              "3243          68  P68I18.JPG  P68I24.JPG  ...      0         0.444444          4\n",
              "2379          60  P60I11.JPG  P60I11.JPG  ...      0         1.000000          9\n",
              "840          176  P176I7.JPG  P176I7.JPG  ...      0         1.000000          9\n",
              "4338          68   P68I9.JPG  P68I27.JPG  ...      1         0.222222          2\n",
              "1662          51  P51I14.JPG   P51I3.JPG  ...      1         0.222222          2\n",
              "4311          68   P68I8.JPG  P68I38.JPG  ...      1         0.333333          3\n",
              "\n",
              "[10 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "em4ff63g2V0R"
      },
      "source": [
        "# Vérifions la performance de chaque expert par rapport au concensus :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCWVHnTr2UvN",
        "outputId": "ee19c632-b1cb-44cd-8afe-b21cc0d879f8"
      },
      "source": [
        "yanal = pd.read_csv('yanal_30_2.csv', sep=';')\n",
        "for expert in [\"E1\",\"E2\",\"E3\",\"E4\",\"E5\",\"E6\",\"E7\",\"E8\",\"E9\"]:\n",
        "  compteur=0\n",
        "  for index in range (len(test[\"path1\"])):\n",
        "\n",
        "    patient_id = test[\"patient_id\"][index]\n",
        "\n",
        "    image1 = test[\"path1\"][index]\n",
        "    nbim_image1 = image1[image1.index(\"I\")+1:image1.index(\".\")]\n",
        "\n",
        "    image2 = test[\"path2\"][index]\n",
        "    nbim_image2 = image2[image2.index(\"I\")+1:image2.index(\".\")]\n",
        "\n",
        "    concensus = test[\"consensus\"][index]/9 #on récupère le concensus normalisé\n",
        "\n",
        "    if int(yanal[ (yanal['patient_id'] == patient_id) & (yanal['image'] == int(nbim_image1) )][expert])== int(yanal[ (yanal['patient_id'] == patient_id) & (yanal['image'] == int(nbim_image2) )][expert]):\n",
        "      compteur = compteur + 1 - ((concensus*9 -1)/8)  #on enlève le biais\n",
        "      #print(1 - ((concensus*9 -1)/8))\n",
        "    else:\n",
        "      compteur = compteur +((concensus*9 +1)/8)\n",
        "      #print(((concensus*9 +1)/8))\n",
        "  print(compteur/len(test[\"path1\"]))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.43068625200826255\n",
            "0.4624741794812945\n",
            "0.42024328666513655\n",
            "0.4228827174661464\n",
            "0.4366536607757631\n",
            "0.44365389029148494\n",
            "0.4924259811797108\n",
            "0.4149644250631168\n",
            "0.43826027082855173\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYkwqc2r4f72"
      },
      "source": [
        "class similiDataset(Dataset):\n",
        "    \"\"\"images dataset\n",
        "    paramètres: \n",
        "    - df: dataframe containing at least 2 columns:\n",
        "                1re colonne avec le nom ou le chemin de chaque image, 2e colonne avec le diagnostic\n",
        "    - root_dir (string): Directory with all the images.\n",
        "    - transform (callable, optional): Optional albumentations transformation to be applied\n",
        "                on the image. \n",
        "    - autocrop (boolean): default is False. automaticaly detect the lesion and crop a square bounding box.\n",
        "        if True, executes before transform and preprocess.\n",
        "    - preprocess (callable, optional): additional transformation using albumentation\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, df, root_dir='', transform=None, colors=False):\n",
        "        self.data_frame = df.copy()\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.colors = colors\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data_frame)\n",
        "    \n",
        "    def mycolors(self, image):\n",
        "      diff = np.mean(image, axis=(0,1)) - np.mean(image)\n",
        "      image2 = image-diff\n",
        "      return image2\n",
        "\n",
        "    def preprocessing(self, img_name):\n",
        "      if not os.path.isfile(img_name):\n",
        "            img_name = img_name.split('.')[0] + '.JPG'\n",
        "            if not os.path.isfile(img_name):\n",
        "              print('not found', img_name)\n",
        "              raise IOError(f'The following file was not found: {img_name}')\n",
        "\n",
        "      image = cv2.imread(img_name)\n",
        "      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "      \n",
        "      if self.transform:\n",
        "          image = self.transform(image=image)['image']\n",
        "\n",
        "      if self.colors:\n",
        "        image = self.mycolors(image)\n",
        "\n",
        "      image = image/255\n",
        "      image = ToTensor()(image=image)['image'].float()\n",
        "      \n",
        "      return image\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        img_name1 = os.path.join(self.root_dir,\n",
        "                                self.data_frame.iloc[idx, 1])\n",
        "        img_name2 = os.path.join(self.root_dir,\n",
        "                                self.data_frame.iloc[idx, 2])\n",
        "\n",
        "      \n",
        "        image1 = self.preprocessing(img_name1)\n",
        "        image2 = self.preprocessing(img_name2)\n",
        "        \n",
        "        label = self.data_frame.iloc[idx, 3]\n",
        "\n",
        "        return image1, image2, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjOgDvqq5uBh"
      },
      "source": [
        "images_path = 'vpc_autocropped_224/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqIX0TCA5uMC"
      },
      "source": [
        "train_transform = A.Compose([A.RandomRotate90(p=1),\n",
        "                             A.HorizontalFlip(p=1),\n",
        "                             A.CLAHE(p=0.5, clip_limit=(1, 5), tile_grid_size=(8, 8)),\n",
        "                             A.GridDistortion(p=0.3, num_steps=5, distort_limit=(-0.3, 0.3), interpolation=0, border_mode=2),\n",
        "                             A.augmentations.transforms.Cutout (num_holes=8, max_h_size=8, max_w_size=8, always_apply=False, p=0.2),\n",
        "                             #A.RandomRain(always_apply=False, p=0.1, slant_lower=-5, slant_upper=5, drop_length=1, drop_width=1, drop_color=(0, 0, 0), blur_value=1, brightness_coefficient=0.8499999642372131, rain_type='drizzle'),\n",
        "                             #A.augmentations.transforms.Normalize ( max_pixel_value=255.0, always_apply=True),\n",
        "                             A.OneOf([\n",
        "                                      #A.augmentations.transforms.ISONoise (color_shift=(0.01, 0.05), intensity=(0.1, 0.5), always_apply=False, p=1),\n",
        "                                      A.augmentations.transforms.RandomBrightnessContrast (brightness_limit=0.2, contrast_limit=0.2, always_apply=False, p=1),\n",
        "                                      A.MotionBlur(blur_limit=3, p=1),\n",
        "                                      A.augmentations.transforms.Blur (blur_limit=3, always_apply=True),\n",
        "                                      #A.MedianBlur(blur_limit=5),\n",
        "                                      #A.GaussianBlur(blur_limit=5,sigma_limit=0),\n",
        "                                      A.GaussNoise(var_limit=(5.0, 50.0)),\n",
        "                                      ], p=0.7),\n",
        "                             ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHriYyqy5uU5"
      },
      "source": [
        "class ResnetMulti9cl(LightningModule):\n",
        "    def __init__(self, hparams):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters(hparams)\n",
        "        self.batch_size = hparams['batch_size']\n",
        "        self.lr = hparams['lr']\n",
        "        self.num_class = hparams['num_class']\n",
        "        self.workers = hparams['workers']\n",
        "        self.test_results = []\n",
        "        self.test_labels = []\n",
        "        \n",
        "        self.model = models.resnet50(pretrained=True)\n",
        "        num_features = self.model.fc.in_features\n",
        "        #self.model.fc = nn.Sequential(nn.Linear(num_features, 1000),\n",
        "        #                              nn.Linear(1000, self.num_class))\n",
        "        self.model.fc = nn.Linear(num_features, self.num_class)\n",
        "        for name, child in self.model.named_children():\n",
        "           if name in ['layer3', 'layer4', 'avgpool', 'fc']:\n",
        "               #print(name + ' is unfrozen')\n",
        "               for param in child.parameters():\n",
        "                   param.requires_grad = True\n",
        "           else:\n",
        "               #print(name + ' is frozen')\n",
        "               for param in child.parameters():\n",
        "                   param.requires_grad = False\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return x\n",
        "ckpt_path_198 = 'epoch=11.ckpt'\n",
        "model_198 = ResnetMulti9cl.load_from_checkpoint(checkpoint_path=ckpt_path_198)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FChhHRz4yR0R"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWyq_nBp5ueC"
      },
      "source": [
        "class Similitude(LightningModule):\n",
        "    def __init__(self, hparams):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters(hparams)\n",
        "    \n",
        "        self.batch_size = hparams['batch_size']\n",
        "        self.lr = hparams['lr']\n",
        "        self.workers = hparams['workers']\n",
        "        \n",
        "        self.test_results = []\n",
        "        self.test_labels = []\n",
        "        \n",
        "        #self.model = models.mobilenet_v2(pretrained=True)\n",
        "        #num_features = self.model.classifier[1].in_features\n",
        "        #self.model.classifier[1] = nn.Linear(num_features, self.num_class)\n",
        "        \n",
        "        self.model = model_198.model\n",
        "        #for params in self.model.parameters():\n",
        "        #  params.requires_grad=False\n",
        "        self.num_features = self.model.fc.in_features\n",
        "        self.model.fc = torch.nn.Linear(self.num_features, 512)\n",
        "        \n",
        "        for name, child in self.model.named_children():\n",
        "           if name in ['layer4', 'avgpool', 'fc']:\n",
        "               #print(name + ' is unfrozen')\n",
        "               for param in child.parameters():\n",
        "                   param.requires_grad = True\n",
        "           else:\n",
        "               #print(name + ' is frozen')\n",
        "               for param in child.parameters():\n",
        "                   param.requires_grad = False\n",
        "\n",
        "    def forward_once(self, x):\n",
        "      output = self.model(x)\n",
        "      return output\n",
        "    \n",
        "    def forward(self, input1, input2):\n",
        "      output1 = self.forward_once(input1)\n",
        "      output2 = self.forward_once(input2)\n",
        "      return output1, output2\n",
        "    \n",
        "    def contrastive_loss(self, euclidean_distance, label):\n",
        "      # perform contrastive loss calculation with the distance\n",
        "      loss_contrastive = torch.mean(\n",
        "          (1-label) * torch.pow(euclidean_distance, 2) +\n",
        "          (label) * torch.pow(torch.clamp(1 - euclidean_distance, min=0.0), 2)\n",
        "          )\n",
        "      return loss_contrastive \n",
        "\n",
        "    def l1(self, logit, label):\n",
        "      return nn.functional.l1_loss(logit.float(), label.float())\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = Adam(self.parameters(), lr=self.lr)\n",
        "        #optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr)\n",
        "        #optimizer = torch.optim.SparseAdam(self.parameters(), lr=self.lr)\n",
        "        #optimizer = torch.optim.ASGD(self.parameters(), lr=self.lr)\n",
        "        #optimizer = torch.optim.RMSprop(self.parameters(), lr=self.lr)\n",
        "        #optimizer = SGD(self.parameters(), lr=self.lr)\n",
        "        #optimizer = torch.optim.Adagrad(self.parameters(), lr=self.lr, lr_decay=0, weight_decay=0, initial_accumulator_value=0, eps=1e-10)\n",
        "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
        "                                                   patience=1, threshold=1e-3, verbose=True)    #https://pytorch.org/docs/stable/optim.html\n",
        "        multistep = lr_scheduler.MultiStepLR(optimizer=optimizer, milestones=[4,12], gamma=0.1, verbose=True)\n",
        "        scheduler_dict = {\n",
        "                      'scheduler': scheduler,\n",
        "                      'interval': 'epoch',\n",
        "                      'monitor': 'val_loss',\n",
        "                      'frequency': 1\n",
        "                  }\n",
        "        return [optimizer], [scheduler_dict]\n",
        "    \n",
        "    def training_step(self, train_batch, batch_id):\n",
        "        x1, x2, y = train_batch\n",
        "        logits1, logits2 = self.forward(x1, x2)\n",
        "        # Find the pairwise distance or eucledian distance of two output feature vectors\n",
        "        euclidean_distance = F.pairwise_distance(logits1, logits2)\n",
        "        #print('distance:', euclidean_distance)\n",
        "        #logits = logits.squeeze()\n",
        "        #loss = self.contrastive_loss(euclidean_distance, y)\n",
        "        loss = self.l1(euclidean_distance, y)\n",
        "\n",
        "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
        "\n",
        "        return {'loss': loss, \n",
        "                'label':y,\n",
        "                'distance':euclidean_distance\n",
        "                }\n",
        "\n",
        "    def training_epoch_end(self, output):\n",
        "        train_distance = torch.cat([x['distance'] for x in output])\n",
        "        labels = torch.cat([x['label'] for x in output])\n",
        "        mae = F.l1_loss(train_distance, labels)\n",
        "        #roc = auroc(train_proba[:,1], labels)\n",
        "        \n",
        "        self.log('train_mae', mae)\n",
        "    \n",
        "    def validation_step(self, valid_batch, batch_id):\n",
        "        x1, x2, y = valid_batch\n",
        "        logits1, logits2 = self.forward(x1, x2)\n",
        "        #logits = logits.squeeze()\n",
        "        euclidean_distance = F.pairwise_distance(logits1, logits2)\n",
        "        #loss = self.contrastive_loss(euclidean_distance, y)\n",
        "        loss = self.l1(euclidean_distance, y)\n",
        "\n",
        "        return {'loss': loss,\n",
        "                'label':y,\n",
        "                'distance':euclidean_distance\n",
        "                }\n",
        "\n",
        "    \n",
        "    def validation_epoch_end(self, output):\n",
        "        avg_loss = torch.stack([x['loss'] for x in output]).mean()\n",
        "        val_distance = torch.cat([x['distance'] for x in output])\n",
        "        labels = torch.cat([x['label'] for x in output])        \n",
        "        mae = F.l1_loss(val_distance, labels)\n",
        "\n",
        "        #tensorboard_logs = {'val_loss': avg_loss, 'valid_roc': roc}\n",
        "        #for key, val in tensorboard_logs.items():\n",
        "        #  self.log(key, val)\n",
        "        self.log('val_loss', avg_loss)\n",
        "        self.log('val_mae', mae)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, y, y_bin = batch\n",
        "        logits = self.forward(x)\n",
        "        #probas = nn.functional.softmax(logits, dim=1)\n",
        "        #print('shape', probas.shape)\n",
        "        #print('probas', probas[0])\n",
        "        return logits\n",
        "        #self.log('test_proba', probas)\n",
        "\n",
        "\n",
        "    def test_step_end(self, output_results):\n",
        "        #all_test_step_outs = output_results.out\n",
        "        probas = nn.functional.softmax(output_results, dim=1)\n",
        "        #loss = nce_loss(all_test_step_outs)\n",
        "        print('all',probas.shape)\n",
        "        #full_probas = torch.cat(output_results)\n",
        "        tensorboard_logs = {'test_proba': output_results}\n",
        "\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(train_data, batch_size=self.batch_size, num_workers=self.workers, shuffle=True)\n",
        "    \n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(valid_data, batch_size=self.batch_size, num_workers=self.workers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-76VUkLI5umh"
      },
      "source": [
        "train_data = similiDataset(train, images_path, transform=train_transform)\n",
        "valid_data = similiDataset(test, images_path, transform=None)\n",
        "hparams = {'batch_size': 30,\n",
        "        'lr':1e-6,\n",
        "        'workers': 2\n",
        "        }\n",
        "\n",
        "\n",
        "model = Similitude(hparams)\n",
        "\n",
        "nep_logger = loggers.NeptuneLogger(api_key=NEPTUNE_API_TOKEN,\n",
        "                                  project_name='charpentier.victor2/tests-similitudes',\n",
        "                                params=hparams,\n",
        "                                experiment_name='siamese',\n",
        "                               tags=['optimizer_ADAM','lr_scheduler.ReduceLROnPlateau','l1_loss', 'new_transform', 'pretrained_198']\n",
        "                               )\n",
        "\n",
        "trainer = Trainer(gpus=1,logger = nep_logger,\n",
        "                  max_epochs=15,\n",
        "                  fast_dev_run=False)\n",
        "\n",
        "\n",
        "trainer.fit(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjD2n5ZR5uu3"
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHkw0T6dESqC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FA0JNXJpDrSy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etkxDCBa5u-0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}